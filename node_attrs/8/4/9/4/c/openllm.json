{
 "archived": false,
 "branch": "main",
 "conda-forge.yml": {
  "bot": {
   "automerge": true
  },
  "conda_build": {
   "error_overlinking": true
  },
  "conda_forge_output_validation": true,
  "github": {
   "branch_name": "main",
   "tooling_branch_name": "main"
  }
 },
 "feedstock_name": "openllm",
 "hash_type": "sha256",
 "linux_64_meta_yaml": {
  "about": {
   "home": "https://github.com/bentoml/OpenLLM",
   "license": "Apache-2.0",
   "license_file": "LICENSE.md",
   "summary": "OpenLLM: Operating LLMs in production"
  },
  "build": {
   "entry_points": [
    "openllm = openllm_cli.entrypoint:cli",
    "openllm-dive-bentos = openllm_cli.extension.dive_bentos:cli",
    "openllm-get-containerfile = openllm_cli.extension.get_containerfile:cli",
    "openllm-get-prompt = openllm_cli.extension.get_prompt:cli",
    "openllm-list-bentos = openllm_cli.extension.list_bentos:cli",
    "openllm-list-models = openllm_cli.extension.list_models:cli",
    "openllm-playground = openllm_cli.extension.playground:cli",
    "openllm = openllm_cli.entrypoint:cli",
    "openllm-dive-bentos = openllm_cli.extension.dive_bentos:cli",
    "openllm-get-containerfile = openllm_cli.extension.get_containerfile:cli",
    "openllm-get-prompt = openllm_cli.extension.get_prompt:cli",
    "openllm-list-bentos = openllm_cli.extension.list_bentos:cli",
    "openllm-list-models = openllm_cli.extension.list_models:cli",
    "openllm-playground = openllm_cli.extension.playground:cli",
    "openllm = openllm_cli.entrypoint:cli",
    "openllm-dive-bentos = openllm_cli.extension.dive_bentos:cli",
    "openllm-get-containerfile = openllm_cli.extension.get_containerfile:cli",
    "openllm-get-prompt = openllm_cli.extension.get_prompt:cli",
    "openllm-list-bentos = openllm_cli.extension.list_bentos:cli",
    "openllm-list-models = openllm_cli.extension.list_models:cli",
    "openllm-playground = openllm_cli.extension.playground:cli",
    "openllm = openllm_cli.entrypoint:cli",
    "openllm-dive-bentos = openllm_cli.extension.dive_bentos:cli",
    "openllm-get-containerfile = openllm_cli.extension.get_containerfile:cli",
    "openllm-get-prompt = openllm_cli.extension.get_prompt:cli",
    "openllm-list-bentos = openllm_cli.extension.list_bentos:cli",
    "openllm-list-models = openllm_cli.extension.list_models:cli",
    "openllm-playground = openllm_cli.extension.playground:cli",
    "openllm = openllm_cli.entrypoint:cli",
    "openllm-dive-bentos = openllm_cli.extension.dive_bentos:cli",
    "openllm-get-containerfile = openllm_cli.extension.get_containerfile:cli",
    "openllm-get-prompt = openllm_cli.extension.get_prompt:cli",
    "openllm-list-bentos = openllm_cli.extension.list_bentos:cli",
    "openllm-list-models = openllm_cli.extension.list_models:cli",
    "openllm-playground = openllm_cli.extension.playground:cli"
   ],
   "number": "1",
   "script": "PYTHON -m pip install . -vv --no-deps --no-build-isolation"
  },
  "extra": {
   "recipe-maintainers": [
    "rxm7706",
    "conda-forge/openllm-client",
    "conda-forge/openllm-core",
    "rxm7706",
    "conda-forge/openllm-client",
    "conda-forge/openllm-core",
    "rxm7706",
    "conda-forge/openllm-client",
    "conda-forge/openllm-core",
    "rxm7706",
    "conda-forge/openllm-client",
    "conda-forge/openllm-core",
    "rxm7706",
    "conda-forge/openllm-client",
    "conda-forge/openllm-core"
   ]
  },
  "package": {
   "name": "openllm",
   "version": "0.4.31"
  },
  "requirements": {
   "host": [
    "python",
    "hatchling ==1.18.0",
    "hatch-vcs ==0.3.0",
    "hatch-fancy-pypi-readme ==23.1.0",
    "pip",
    "python",
    "hatchling ==1.18.0",
    "hatch-vcs ==0.3.0",
    "hatch-fancy-pypi-readme ==23.1.0",
    "pip",
    "python",
    "hatchling ==1.18.0",
    "hatch-vcs ==0.3.0",
    "hatch-fancy-pypi-readme ==23.1.0",
    "pip",
    "python",
    "hatchling ==1.18.0",
    "hatch-vcs ==0.3.0",
    "hatch-fancy-pypi-readme ==23.1.0",
    "pip",
    "python",
    "hatchling ==1.18.0",
    "hatch-vcs ==0.3.0",
    "hatch-fancy-pypi-readme ==23.1.0",
    "pip"
   ],
   "run": [
    "python",
    "bentoml >=1.1.10",
    "transformers >=4.35.0",
    "openllm-client >=0.4.31",
    "openllm-core >=0.4.31",
    "safetensors",
    "optimum >=1.12.0",
    "accelerate",
    "ghapi",
    "einops",
    "sentencepiece",
    "scipy",
    "python-build <1",
    "click >=8.1.3",
    "cuda-python",
    "bitsandbytes <0.42",
    "python",
    "bentoml >=1.1.10",
    "transformers >=4.35.0",
    "openllm-client >=0.4.31",
    "openllm-core >=0.4.31",
    "safetensors",
    "optimum >=1.12.0",
    "accelerate",
    "ghapi",
    "einops",
    "sentencepiece",
    "scipy",
    "python-build <1",
    "click >=8.1.3",
    "cuda-python",
    "bitsandbytes <0.42",
    "python",
    "bentoml >=1.1.10",
    "transformers >=4.35.0",
    "openllm-client >=0.4.31",
    "openllm-core >=0.4.31",
    "safetensors",
    "optimum >=1.12.0",
    "accelerate",
    "ghapi",
    "einops",
    "sentencepiece",
    "scipy",
    "python-build <1",
    "click >=8.1.3",
    "cuda-python",
    "bitsandbytes <0.42",
    "python",
    "bentoml >=1.1.10",
    "transformers >=4.35.0",
    "openllm-client >=0.4.31",
    "openllm-core >=0.4.31",
    "safetensors",
    "optimum >=1.12.0",
    "accelerate",
    "ghapi",
    "einops",
    "sentencepiece",
    "scipy",
    "python-build <1",
    "click >=8.1.3",
    "cuda-python",
    "bitsandbytes <0.42",
    "python",
    "bentoml >=1.1.10",
    "transformers >=4.35.0",
    "openllm-client >=0.4.31",
    "openllm-core >=0.4.31",
    "safetensors",
    "optimum >=1.12.0",
    "accelerate",
    "ghapi",
    "einops",
    "sentencepiece",
    "scipy",
    "python-build <1",
    "click >=8.1.3",
    "cuda-python",
    "bitsandbytes <0.42"
   ]
  },
  "source": {
   "sha256": "cd2850a6c46b8f801325265a8b7e91ee193a8acfb848deccb7efc6273ee91895",
   "url": "https://pypi.io/packages/source/o/openllm/openllm-0.4.31.tar.gz"
  },
  "test": {
   "commands": [
    "pip check",
    "openllm --help",
    "openllm-dive-bentos --help",
    "openllm-get-containerfile --help",
    "openllm-get-prompt --help",
    "openllm-list-bentos --help",
    "openllm-list-models --help",
    "pip check",
    "openllm --help",
    "openllm-dive-bentos --help",
    "openllm-get-containerfile --help",
    "openllm-get-prompt --help",
    "openllm-list-bentos --help",
    "openllm-list-models --help",
    "pip check",
    "openllm --help",
    "openllm-dive-bentos --help",
    "openllm-get-containerfile --help",
    "openllm-get-prompt --help",
    "openllm-list-bentos --help",
    "openllm-list-models --help",
    "pip check",
    "openllm --help",
    "openllm-dive-bentos --help",
    "openllm-get-containerfile --help",
    "openllm-get-prompt --help",
    "openllm-list-bentos --help",
    "openllm-list-models --help",
    "pip check",
    "openllm --help",
    "openllm-dive-bentos --help",
    "openllm-get-containerfile --help",
    "openllm-get-prompt --help",
    "openllm-list-bentos --help",
    "openllm-list-models --help"
   ],
   "imports": [
    "openllm",
    "openllm",
    "openllm",
    "openllm",
    "openllm"
   ],
   "requires": [
    "pip",
    "pip",
    "pip",
    "pip",
    "pip"
   ]
  }
 },
 "linux_64_requirements": {
  "build": {
   "__set__": true,
   "elements": []
  },
  "host": {
   "__set__": true,
   "elements": [
    "hatch-fancy-pypi-readme",
    "hatch-vcs",
    "hatchling",
    "pip",
    "python"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "accelerate",
    "bentoml",
    "bitsandbytes",
    "click",
    "cuda-python",
    "einops",
    "ghapi",
    "openllm-client",
    "openllm-core",
    "optimum",
    "python",
    "python-build",
    "safetensors",
    "scipy",
    "sentencepiece",
    "transformers"
   ]
  },
  "test": {
   "__set__": true,
   "elements": [
    "pip"
   ]
  }
 },
 "meta_yaml": {
  "about": {
   "home": "https://github.com/bentoml/OpenLLM",
   "license": "Apache-2.0",
   "license_file": "LICENSE.md",
   "summary": "OpenLLM: Operating LLMs in production"
  },
  "build": {
   "entry_points": [
    "openllm = openllm_cli.entrypoint:cli",
    "openllm-dive-bentos = openllm_cli.extension.dive_bentos:cli",
    "openllm-get-containerfile = openllm_cli.extension.get_containerfile:cli",
    "openllm-get-prompt = openllm_cli.extension.get_prompt:cli",
    "openllm-list-bentos = openllm_cli.extension.list_bentos:cli",
    "openllm-list-models = openllm_cli.extension.list_models:cli",
    "openllm-playground = openllm_cli.extension.playground:cli",
    "openllm = openllm_cli.entrypoint:cli",
    "openllm-dive-bentos = openllm_cli.extension.dive_bentos:cli",
    "openllm-get-containerfile = openllm_cli.extension.get_containerfile:cli",
    "openllm-get-prompt = openllm_cli.extension.get_prompt:cli",
    "openllm-list-bentos = openllm_cli.extension.list_bentos:cli",
    "openllm-list-models = openllm_cli.extension.list_models:cli",
    "openllm-playground = openllm_cli.extension.playground:cli",
    "openllm = openllm_cli.entrypoint:cli",
    "openllm-dive-bentos = openllm_cli.extension.dive_bentos:cli",
    "openllm-get-containerfile = openllm_cli.extension.get_containerfile:cli",
    "openllm-get-prompt = openllm_cli.extension.get_prompt:cli",
    "openllm-list-bentos = openllm_cli.extension.list_bentos:cli",
    "openllm-list-models = openllm_cli.extension.list_models:cli",
    "openllm-playground = openllm_cli.extension.playground:cli",
    "openllm = openllm_cli.entrypoint:cli",
    "openllm-dive-bentos = openllm_cli.extension.dive_bentos:cli",
    "openllm-get-containerfile = openllm_cli.extension.get_containerfile:cli",
    "openllm-get-prompt = openllm_cli.extension.get_prompt:cli",
    "openllm-list-bentos = openllm_cli.extension.list_bentos:cli",
    "openllm-list-models = openllm_cli.extension.list_models:cli",
    "openllm-playground = openllm_cli.extension.playground:cli",
    "openllm = openllm_cli.entrypoint:cli",
    "openllm-dive-bentos = openllm_cli.extension.dive_bentos:cli",
    "openllm-get-containerfile = openllm_cli.extension.get_containerfile:cli",
    "openllm-get-prompt = openllm_cli.extension.get_prompt:cli",
    "openllm-list-bentos = openllm_cli.extension.list_bentos:cli",
    "openllm-list-models = openllm_cli.extension.list_models:cli",
    "openllm-playground = openllm_cli.extension.playground:cli"
   ],
   "number": "1",
   "script": "PYTHON -m pip install . -vv --no-deps --no-build-isolation"
  },
  "extra": {
   "recipe-maintainers": [
    "rxm7706",
    "conda-forge/openllm-client",
    "conda-forge/openllm-core",
    "rxm7706",
    "conda-forge/openllm-client",
    "conda-forge/openllm-core",
    "rxm7706",
    "conda-forge/openllm-client",
    "conda-forge/openllm-core",
    "rxm7706",
    "conda-forge/openllm-client",
    "conda-forge/openllm-core",
    "rxm7706",
    "conda-forge/openllm-client",
    "conda-forge/openllm-core"
   ]
  },
  "package": {
   "name": "openllm",
   "version": "0.4.31"
  },
  "requirements": {
   "host": [
    "python",
    "hatchling ==1.18.0",
    "hatch-vcs ==0.3.0",
    "hatch-fancy-pypi-readme ==23.1.0",
    "pip",
    "python",
    "hatchling ==1.18.0",
    "hatch-vcs ==0.3.0",
    "hatch-fancy-pypi-readme ==23.1.0",
    "pip",
    "python",
    "hatchling ==1.18.0",
    "hatch-vcs ==0.3.0",
    "hatch-fancy-pypi-readme ==23.1.0",
    "pip",
    "python",
    "hatchling ==1.18.0",
    "hatch-vcs ==0.3.0",
    "hatch-fancy-pypi-readme ==23.1.0",
    "pip",
    "python",
    "hatchling ==1.18.0",
    "hatch-vcs ==0.3.0",
    "hatch-fancy-pypi-readme ==23.1.0",
    "pip"
   ],
   "run": [
    "python",
    "bentoml >=1.1.10",
    "transformers >=4.35.0",
    "openllm-client >=0.4.31",
    "openllm-core >=0.4.31",
    "safetensors",
    "optimum >=1.12.0",
    "accelerate",
    "ghapi",
    "einops",
    "sentencepiece",
    "scipy",
    "python-build <1",
    "click >=8.1.3",
    "cuda-python",
    "bitsandbytes <0.42",
    "python",
    "bentoml >=1.1.10",
    "transformers >=4.35.0",
    "openllm-client >=0.4.31",
    "openllm-core >=0.4.31",
    "safetensors",
    "optimum >=1.12.0",
    "accelerate",
    "ghapi",
    "einops",
    "sentencepiece",
    "scipy",
    "python-build <1",
    "click >=8.1.3",
    "cuda-python",
    "bitsandbytes <0.42",
    "python",
    "bentoml >=1.1.10",
    "transformers >=4.35.0",
    "openllm-client >=0.4.31",
    "openllm-core >=0.4.31",
    "safetensors",
    "optimum >=1.12.0",
    "accelerate",
    "ghapi",
    "einops",
    "sentencepiece",
    "scipy",
    "python-build <1",
    "click >=8.1.3",
    "cuda-python",
    "bitsandbytes <0.42",
    "python",
    "bentoml >=1.1.10",
    "transformers >=4.35.0",
    "openllm-client >=0.4.31",
    "openllm-core >=0.4.31",
    "safetensors",
    "optimum >=1.12.0",
    "accelerate",
    "ghapi",
    "einops",
    "sentencepiece",
    "scipy",
    "python-build <1",
    "click >=8.1.3",
    "cuda-python",
    "bitsandbytes <0.42",
    "python",
    "bentoml >=1.1.10",
    "transformers >=4.35.0",
    "openllm-client >=0.4.31",
    "openllm-core >=0.4.31",
    "safetensors",
    "optimum >=1.12.0",
    "accelerate",
    "ghapi",
    "einops",
    "sentencepiece",
    "scipy",
    "python-build <1",
    "click >=8.1.3",
    "cuda-python",
    "bitsandbytes <0.42"
   ]
  },
  "source": {
   "sha256": "cd2850a6c46b8f801325265a8b7e91ee193a8acfb848deccb7efc6273ee91895",
   "url": "https://pypi.io/packages/source/o/openllm/openllm-0.4.31.tar.gz"
  },
  "test": {
   "commands": [
    "pip check",
    "openllm --help",
    "openllm-dive-bentos --help",
    "openllm-get-containerfile --help",
    "openllm-get-prompt --help",
    "openllm-list-bentos --help",
    "openllm-list-models --help",
    "pip check",
    "openllm --help",
    "openllm-dive-bentos --help",
    "openllm-get-containerfile --help",
    "openllm-get-prompt --help",
    "openllm-list-bentos --help",
    "openllm-list-models --help",
    "pip check",
    "openllm --help",
    "openllm-dive-bentos --help",
    "openllm-get-containerfile --help",
    "openllm-get-prompt --help",
    "openllm-list-bentos --help",
    "openllm-list-models --help",
    "pip check",
    "openllm --help",
    "openllm-dive-bentos --help",
    "openllm-get-containerfile --help",
    "openllm-get-prompt --help",
    "openllm-list-bentos --help",
    "openllm-list-models --help",
    "pip check",
    "openllm --help",
    "openllm-dive-bentos --help",
    "openllm-get-containerfile --help",
    "openllm-get-prompt --help",
    "openllm-list-bentos --help",
    "openllm-list-models --help"
   ],
   "imports": [
    "openllm",
    "openllm",
    "openllm",
    "openllm",
    "openllm"
   ],
   "requires": [
    "pip",
    "pip",
    "pip",
    "pip",
    "pip"
   ]
  }
 },
 "name": "openllm",
 "outputs_names": {
  "__set__": true,
  "elements": [
   "openllm"
  ]
 },
 "parsing_error": false,
 "platforms": [
  "linux_64"
 ],
 "pr_info": {
  "__lazy_json__": "pr_info/openllm.json"
 },
 "raw_meta_yaml": "{% set name = \"openllm\" %}\n{% set version = \"0.4.31\" %}\n\npackage:\n  name: {{ name|lower }}\n  version: {{ version }}\n\nsource:\n  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/openllm-{{ version }}.tar.gz\n  sha256: cd2850a6c46b8f801325265a8b7e91ee193a8acfb848deccb7efc6273ee91895\n\nbuild:\n  skip: true  # [win or osx]\n  skip: true  # [py<38]\n  entry_points:\n    - openllm = openllm_cli.entrypoint:cli\n    - openllm-dive-bentos = openllm_cli.extension.dive_bentos:cli\n    - openllm-get-containerfile = openllm_cli.extension.get_containerfile:cli\n    - openllm-get-prompt = openllm_cli.extension.get_prompt:cli\n    - openllm-list-bentos = openllm_cli.extension.list_bentos:cli\n    - openllm-list-models = openllm_cli.extension.list_models:cli\n    - openllm-playground = openllm_cli.extension.playground:cli\n  script: {{ PYTHON }} -m pip install . -vv --no-deps --no-build-isolation\n  number: 1\n\nrequirements:\n  host:\n    - python\n    - hatchling ==1.18.0\n    - hatch-vcs ==0.3.0\n    - hatch-fancy-pypi-readme ==23.1.0\n    - pip\n  run:\n    - python\n    - bentoml >=1.1.10\n    - transformers >=4.35.0\n    - openllm-client >=0.4.31\n    - openllm-core >=0.4.31\n    - safetensors\n    - optimum >=1.12.0\n    - accelerate\n    - ghapi\n    - einops\n    - sentencepiece\n    - scipy\n    - python-build <1\n    - click >=8.1.3\n    - cuda-python\n    - bitsandbytes <0.42\n\ntest:\n  imports:\n    - openllm\n  commands:\n    - pip check\n    - openllm --help\n    - openllm-dive-bentos --help\n    - openllm-get-containerfile --help\n    - openllm-get-prompt --help\n    - openllm-list-bentos --help\n    - openllm-list-models --help\n  requires:\n    - pip\n\nabout:\n  summary: 'OpenLLM: Operating LLMs in production'\n  home: https://github.com/bentoml/OpenLLM\n  license: Apache-2.0\n  license_file: LICENSE.md\n\nextra:\n  recipe-maintainers:\n    - rxm7706\n    - conda-forge/openllm-client\n    - conda-forge/openllm-core\n",
 "req": {
  "__set__": true,
  "elements": [
   "accelerate",
   "bentoml",
   "bitsandbytes",
   "click",
   "cuda-python",
   "einops",
   "ghapi",
   "hatch-fancy-pypi-readme",
   "hatch-vcs",
   "hatchling",
   "openllm-client",
   "openllm-core",
   "optimum",
   "pip",
   "python",
   "python-build",
   "safetensors",
   "scipy",
   "sentencepiece",
   "transformers"
  ]
 },
 "requirements": {
  "build": {
   "__set__": true,
   "elements": []
  },
  "host": {
   "__set__": true,
   "elements": [
    "hatch-fancy-pypi-readme",
    "hatch-vcs",
    "hatchling",
    "pip",
    "python"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "accelerate",
    "bentoml",
    "bitsandbytes",
    "click",
    "cuda-python",
    "einops",
    "ghapi",
    "openllm-client",
    "openllm-core",
    "optimum",
    "python",
    "python-build",
    "safetensors",
    "scipy",
    "sentencepiece",
    "transformers"
   ]
  },
  "test": {
   "__set__": true,
   "elements": [
    "pip"
   ]
  }
 },
 "strong_exports": false,
 "total_requirements": {
  "build": {
   "__set__": true,
   "elements": []
  },
  "host": {
   "__set__": true,
   "elements": [
    "hatch-fancy-pypi-readme ==23.1.0",
    "hatch-vcs ==0.3.0",
    "hatchling ==1.18.0",
    "pip",
    "python"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "accelerate",
    "bentoml >=1.1.10",
    "bitsandbytes <0.42",
    "click >=8.1.3",
    "cuda-python",
    "einops",
    "ghapi",
    "openllm-client >=0.4.31",
    "openllm-core >=0.4.31",
    "optimum >=1.12.0",
    "python",
    "python-build <1",
    "safetensors",
    "scipy",
    "sentencepiece",
    "transformers >=4.35.0"
   ]
  },
  "test": {
   "__set__": true,
   "elements": [
    "pip"
   ]
  }
 },
 "url": "https://pypi.io/packages/source/o/openllm/openllm-0.4.31.tar.gz",
 "version": "0.4.31",
 "version_pr_info": {
  "__lazy_json__": "version_pr_info/openllm.json"
 }
}