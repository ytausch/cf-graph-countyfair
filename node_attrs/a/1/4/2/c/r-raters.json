{
 "archived": false,
 "branch": "main",
 "conda-forge.yml": {
  "bot": {
   "automerge": true
  },
  "conda_build": {
   "pkg_format": "2"
  },
  "conda_forge_output_validation": true,
  "github": {
   "branch_name": "main",
   "tooling_branch_name": "main"
  }
 },
 "feedstock_name": "r-raters",
 "hash_type": "sha256",
 "linux_64_meta_yaml": {
  "about": {
   "home": "https://CRAN.R-project.org/package=raters",
   "license": "GPL-2.0-or-later",
   "license_family": "GPL2",
   "license_file": [
    "/lib/R/share/licenses/GPL-2",
    "/lib/R/share/licenses/GPL-2"
   ],
   "summary": "The kappa statistic implemented by Fleiss is a very popular index for assessing the reliability of agreement among multiple observers. It is used both in the psychological and in the psychiatric field. Other fields of application are typically medicine, biology and engineering. Unfortunately,the kappa statistic may behave inconsistently in case of strong agreement between raters, since this index assumes lower values than it would have been expected. We propose a modification kappa implemented by Fleiss in case of nominal and ordinal variables. Monte Carlo simulations are used both to testing statistical hypotheses and to calculating percentile bootstrap confidence intervals based on proposed statistic in case of nominal and ordinal data."
  },
  "build": {
   "noarch": "generic",
   "number": "0",
   "rpaths": [
    "lib/R/lib/",
    "lib/",
    "lib/R/lib/",
    "lib/"
   ]
  },
  "extra": {
   "recipe-maintainers": [
    "conda-forge/r",
    "conda-forge/r"
   ]
  },
  "package": {
   "name": "r-raters",
   "version": "2.0.3"
  },
  "requirements": {
   "build": [],
   "host": [
    "r-base",
    "r-base"
   ],
   "run": [
    "r-base",
    "r-base"
   ]
  },
  "source": {
   "sha256": "f4f72fbac31ecaa0753f2886dbf62de9266783eb398616e72175e4b46521135b",
   "url": [
    "https://cran.r-project.org/src/contrib/raters_2.0.3.tar.gz",
    "https://cran.r-project.org/src/contrib/Archive/raters/raters_2.0.3.tar.gz",
    "https://cran.r-project.org/src/contrib/raters_2.0.3.tar.gz",
    "https://cran.r-project.org/src/contrib/Archive/raters/raters_2.0.3.tar.gz"
   ]
  },
  "test": {
   "commands": [
    "$R -e \"library('raters')\"",
    "$R -e \"library('raters')\""
   ]
  }
 },
 "linux_64_requirements": {
  "build": {
   "__set__": true,
   "elements": []
  },
  "host": {
   "__set__": true,
   "elements": [
    "r-base"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "r-base"
   ]
  },
  "test": {
   "__set__": true,
   "elements": []
  }
 },
 "meta_yaml": {
  "about": {
   "home": "https://CRAN.R-project.org/package=raters",
   "license": "GPL-2.0-or-later",
   "license_family": "GPL2",
   "license_file": [
    "/lib/R/share/licenses/GPL-2",
    "/lib/R/share/licenses/GPL-2"
   ],
   "summary": "The kappa statistic implemented by Fleiss is a very popular index for assessing the reliability of agreement among multiple observers. It is used both in the psychological and in the psychiatric field. Other fields of application are typically medicine, biology and engineering. Unfortunately,the kappa statistic may behave inconsistently in case of strong agreement between raters, since this index assumes lower values than it would have been expected. We propose a modification kappa implemented by Fleiss in case of nominal and ordinal variables. Monte Carlo simulations are used both to testing statistical hypotheses and to calculating percentile bootstrap confidence intervals based on proposed statistic in case of nominal and ordinal data."
  },
  "build": {
   "noarch": "generic",
   "number": "0",
   "rpaths": [
    "lib/R/lib/",
    "lib/",
    "lib/R/lib/",
    "lib/"
   ]
  },
  "extra": {
   "recipe-maintainers": [
    "conda-forge/r",
    "conda-forge/r"
   ]
  },
  "package": {
   "name": "r-raters",
   "version": "2.0.3"
  },
  "requirements": {
   "build": [],
   "host": [
    "r-base",
    "r-base"
   ],
   "run": [
    "r-base",
    "r-base"
   ]
  },
  "source": {
   "sha256": "f4f72fbac31ecaa0753f2886dbf62de9266783eb398616e72175e4b46521135b",
   "url": [
    "https://cran.r-project.org/src/contrib/raters_2.0.3.tar.gz",
    "https://cran.r-project.org/src/contrib/Archive/raters/raters_2.0.3.tar.gz",
    "https://cran.r-project.org/src/contrib/raters_2.0.3.tar.gz",
    "https://cran.r-project.org/src/contrib/Archive/raters/raters_2.0.3.tar.gz"
   ]
  },
  "test": {
   "commands": [
    "$R -e \"library('raters')\"",
    "$R -e \"library('raters')\""
   ]
  }
 },
 "name": "r-raters",
 "outputs_names": {
  "__set__": true,
  "elements": [
   "r-raters"
  ]
 },
 "parsing_error": false,
 "platforms": [
  "linux_64"
 ],
 "pr_info": {
  "__lazy_json__": "pr_info/r-raters.json"
 },
 "raw_meta_yaml": "{% set version = \"2.0.3\" %}\n{% set posix = 'm2-' if win else '' %}\n{% set native = 'm2w64-' if win else '' %}\n\npackage:\n  name: r-raters\n  version: {{ version|replace(\"-\", \"_\") }}\n\nsource:\n  url:\n    - {{ cran_mirror }}/src/contrib/raters_{{ version }}.tar.gz\n    - {{ cran_mirror }}/src/contrib/Archive/raters/raters_{{ version }}.tar.gz\n  sha256: f4f72fbac31ecaa0753f2886dbf62de9266783eb398616e72175e4b46521135b\n\nbuild:\n  merge_build_host: true  # [win]\n  number: 0\n  noarch: generic\n  rpaths:\n    - lib/R/lib/\n    - lib/\n\nrequirements:\n  build:\n    - {{ posix }}zip               # [win]\n  host:\n    - r-base\n  run:\n    - r-base\n\ntest:\n  commands:\n    - $R -e \"library('raters')\"           # [not win]\n    - \"\\\"%R%\\\" -e \\\"library('raters')\\\"\"  # [win]\n\nabout:\n  home: https://CRAN.R-project.org/package=raters\n  license: GPL-2.0-or-later\n  summary: The kappa statistic implemented by Fleiss is a very popular index for assessing the reliability of agreement among multiple observers. It is used both in the psychological and in the psychiatric field. Other fields of application are typically medicine, biology and engineering. Unfortunately,the kappa statistic\n    may behave inconsistently in case of strong agreement between raters, since this index assumes lower values than it would have been expected. We propose a modification kappa implemented by Fleiss in case of nominal and ordinal variables. Monte Carlo simulations are used both to testing statistical hypotheses and to calculating\n    percentile bootstrap confidence intervals based on proposed statistic in case of nominal and ordinal data.\n  license_family: GPL2\n  license_file:\n    - {{ environ[\"PREFIX\"] }}/lib/R/share/licenses/GPL-2\n\nextra:\n  recipe-maintainers:\n    - conda-forge/r\n\n# Package: raters\n# Type: Package\n# Title: A Modification of Fleiss' Kappa in Case of Nominal and Ordinal Variables\n# Authors@R: c(person(\"Daniele\", \"Giardiello\", role =\"cre\", email = \"daniele.giardiello1@gmail.com\"), person(\"Piero\", \"Quatto\", role = \"aut\", email = \"piero.quatto@unimib.it\"), person(\"Enrico\", \"Ripamonti\", role = \"aut\"), person(\"Stefano\", \"Vigliani\", role = \"ctb\", email=\"stefano.vigliani@izsler.it\"))\n# Version: 2.0.1\n# Date: 2014-12-29\n# Author: Daniele Giardiello [cre], Piero Quatto [aut], Enrico Ripamonti [aut], Stefano Vigliani [ctb]\n# Maintainer: Daniele Giardiello <daniele.giardiello1@gmail.com>\n# License: GPL (>= 2)\n# Description: The kappa statistic implemented by Fleiss is a very popular index for assessing the reliability of agreement among multiple observers. It is used both in the psychological and in the psychiatric field. Other fields of application are typically medicine, biology and engineering. Unfortunately,the kappa statistic may behave inconsistently in case of strong agreement between raters, since this index assumes lower values than it would have been expected. We propose a modification kappa implemented by Fleiss in case of nominal and ordinal variables. Monte Carlo simulations are used both to testing statistical hypotheses and to calculating percentile bootstrap confidence intervals based on proposed statistic in case of nominal and ordinal data.\n# Packaged: 2014-12-29 14:14:50 UTC; GiardielloDaniele\n# NeedsCompilation: no\n# Repository: CRAN\n# Date/Publication: 2014-12-29 15:26:51\n",
 "req": {
  "__set__": true,
  "elements": [
   "r-base"
  ]
 },
 "requirements": {
  "build": {
   "__set__": true,
   "elements": []
  },
  "host": {
   "__set__": true,
   "elements": [
    "r-base"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "r-base"
   ]
  },
  "test": {
   "__set__": true,
   "elements": []
  }
 },
 "strong_exports": false,
 "total_requirements": {
  "build": {
   "__set__": true,
   "elements": []
  },
  "host": {
   "__set__": true,
   "elements": [
    "r-base"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "r-base"
   ]
  },
  "test": {
   "__set__": true,
   "elements": []
  }
 },
 "url": [
  "https://cran.r-project.org/src/contrib/raters_2.0.3.tar.gz",
  "https://cran.r-project.org/src/contrib/Archive/raters/raters_2.0.3.tar.gz",
  "https://cran.r-project.org/src/contrib/raters_2.0.3.tar.gz",
  "https://cran.r-project.org/src/contrib/Archive/raters/raters_2.0.3.tar.gz"
 ],
 "version": "2.0.3",
 "version_pr_info": {
  "__lazy_json__": "version_pr_info/r-raters.json"
 }
}