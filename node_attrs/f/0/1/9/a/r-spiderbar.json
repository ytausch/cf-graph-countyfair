{
 "archived": false,
 "branch": "main",
 "conda-forge.yml": {
  "conda_build": {
   "error_overlinking": true
  },
  "conda_forge_output_validation": true,
  "github": {
   "branch_name": "main",
   "tooling_branch_name": "main"
  }
 },
 "feedstock_name": "r-spiderbar",
 "hash_type": "sha256",
 "linux_64_meta_yaml": {
  "about": {
   "home": "https://github.com/hrbrmstr/spiderbar",
   "license": "MIT",
   "license_family": "MIT",
   "license_file": [
    "/lib/R/share/licenses/MIT",
    "LICENSE",
    "/lib/R/share/licenses/MIT",
    "LICENSE"
   ],
   "summary": "The 'Robots Exclusion Protocol' <https://www.robotstxt.org/orig.html> documents a set of standards for allowing or excluding robot/spider crawling of different areas of site content. Tools are provided which wrap The 'rep-cpp' <https://github.com/seomoz/rep-cpp> C++ library for processing these 'robots.txt' files."
  },
  "build": {
   "number": "0",
   "rpaths": [
    "lib/R/lib/",
    "lib/",
    "lib/R/lib/",
    "lib/"
   ]
  },
  "extra": {
   "recipe-maintainers": [
    "conda-forge/r",
    "conda-forge/r"
   ]
  },
  "package": {
   "name": "r-spiderbar",
   "version": "0.2.5"
  },
  "requirements": {
   "build": [
    "c_compiler_stub",
    "cxx_compiler_stub",
    "make",
    "c_compiler_stub",
    "cxx_compiler_stub",
    "make"
   ],
   "host": [
    "r-base",
    "r-rcpp",
    "r-base",
    "r-rcpp"
   ],
   "run": [
    "r-base",
    "r-rcpp",
    "r-base",
    "r-rcpp"
   ]
  },
  "source": {
   "sha256": "45b7f1c28d7764319d5222f170dd7c0733a8400ff5d2a9aba9d5f7a4eda81d7a",
   "url": [
    "https://cran.r-project.org/src/contrib/spiderbar_0.2.5.tar.gz",
    "https://cran.r-project.org/src/contrib/Archive/spiderbar/spiderbar_0.2.5.tar.gz",
    "https://cran.r-project.org/src/contrib/spiderbar_0.2.5.tar.gz",
    "https://cran.r-project.org/src/contrib/Archive/spiderbar/spiderbar_0.2.5.tar.gz"
   ]
  },
  "test": {
   "commands": [
    "$R -e \"library('spiderbar')\"",
    "$R -e \"library('spiderbar')\""
   ]
  }
 },
 "linux_64_requirements": {
  "build": {
   "__set__": true,
   "elements": [
    "c_compiler_stub",
    "cxx_compiler_stub",
    "make"
   ]
  },
  "host": {
   "__set__": true,
   "elements": [
    "r-base",
    "r-rcpp"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "r-base",
    "r-rcpp"
   ]
  },
  "test": {
   "__set__": true,
   "elements": []
  }
 },
 "meta_yaml": {
  "about": {
   "home": "https://github.com/hrbrmstr/spiderbar",
   "license": "MIT",
   "license_family": "MIT",
   "license_file": [
    "/lib/R/share/licenses/MIT",
    "LICENSE",
    "/lib/R/share/licenses/MIT",
    "LICENSE",
    "/lib/R/share/licenses/MIT",
    "LICENSE",
    "/lib/R/share/licenses/MIT",
    "LICENSE"
   ],
   "summary": "The 'Robots Exclusion Protocol' <https://www.robotstxt.org/orig.html> documents a set of standards for allowing or excluding robot/spider crawling of different areas of site content. Tools are provided which wrap The 'rep-cpp' <https://github.com/seomoz/rep-cpp> C++ library for processing these 'robots.txt' files."
  },
  "build": {
   "number": "0",
   "rpaths": [
    "lib/R/lib/",
    "lib/",
    "lib/R/lib/",
    "lib/",
    "lib/R/lib/",
    "lib/",
    "lib/R/lib/",
    "lib/"
   ]
  },
  "extra": {
   "recipe-maintainers": [
    "conda-forge/r",
    "conda-forge/r",
    "conda-forge/r",
    "conda-forge/r"
   ]
  },
  "package": {
   "name": "r-spiderbar",
   "version": "0.2.5"
  },
  "requirements": {
   "build": [
    "c_compiler_stub",
    "cxx_compiler_stub",
    "make",
    "c_compiler_stub",
    "cxx_compiler_stub",
    "make",
    "c_compiler_stub",
    "cxx_compiler_stub",
    "make",
    "c_compiler_stub",
    "cxx_compiler_stub",
    "make"
   ],
   "host": [
    "r-base",
    "r-rcpp",
    "r-base",
    "r-rcpp",
    "r-base",
    "r-rcpp",
    "r-base",
    "r-rcpp"
   ],
   "run": [
    "r-base",
    "r-rcpp",
    "r-base",
    "r-rcpp",
    "r-base",
    "r-rcpp",
    "r-base",
    "r-rcpp"
   ]
  },
  "source": {
   "sha256": "45b7f1c28d7764319d5222f170dd7c0733a8400ff5d2a9aba9d5f7a4eda81d7a",
   "url": [
    "https://cran.r-project.org/src/contrib/spiderbar_0.2.5.tar.gz",
    "https://cran.r-project.org/src/contrib/Archive/spiderbar/spiderbar_0.2.5.tar.gz",
    "https://cran.r-project.org/src/contrib/spiderbar_0.2.5.tar.gz",
    "https://cran.r-project.org/src/contrib/Archive/spiderbar/spiderbar_0.2.5.tar.gz",
    "https://cran.r-project.org/src/contrib/spiderbar_0.2.5.tar.gz",
    "https://cran.r-project.org/src/contrib/Archive/spiderbar/spiderbar_0.2.5.tar.gz",
    "https://cran.r-project.org/src/contrib/spiderbar_0.2.5.tar.gz",
    "https://cran.r-project.org/src/contrib/Archive/spiderbar/spiderbar_0.2.5.tar.gz"
   ]
  },
  "test": {
   "commands": [
    "$R -e \"library('spiderbar')\"",
    "$R -e \"library('spiderbar')\"",
    "$R -e \"library('spiderbar')\"",
    "$R -e \"library('spiderbar')\""
   ]
  }
 },
 "name": "r-spiderbar",
 "osx_64_meta_yaml": {
  "about": {
   "home": "https://github.com/hrbrmstr/spiderbar",
   "license": "MIT",
   "license_family": "MIT",
   "license_file": [
    "/lib/R/share/licenses/MIT",
    "LICENSE",
    "/lib/R/share/licenses/MIT",
    "LICENSE"
   ],
   "summary": "The 'Robots Exclusion Protocol' <https://www.robotstxt.org/orig.html> documents a set of standards for allowing or excluding robot/spider crawling of different areas of site content. Tools are provided which wrap The 'rep-cpp' <https://github.com/seomoz/rep-cpp> C++ library for processing these 'robots.txt' files."
  },
  "build": {
   "number": "0",
   "rpaths": [
    "lib/R/lib/",
    "lib/",
    "lib/R/lib/",
    "lib/"
   ]
  },
  "extra": {
   "recipe-maintainers": [
    "conda-forge/r",
    "conda-forge/r"
   ]
  },
  "package": {
   "name": "r-spiderbar",
   "version": "0.2.5"
  },
  "requirements": {
   "build": [
    "c_compiler_stub",
    "cxx_compiler_stub",
    "make",
    "c_compiler_stub",
    "cxx_compiler_stub",
    "make"
   ],
   "host": [
    "r-base",
    "r-rcpp",
    "r-base",
    "r-rcpp"
   ],
   "run": [
    "r-base",
    "r-rcpp",
    "r-base",
    "r-rcpp"
   ]
  },
  "source": {
   "sha256": "45b7f1c28d7764319d5222f170dd7c0733a8400ff5d2a9aba9d5f7a4eda81d7a",
   "url": [
    "https://cran.r-project.org/src/contrib/spiderbar_0.2.5.tar.gz",
    "https://cran.r-project.org/src/contrib/Archive/spiderbar/spiderbar_0.2.5.tar.gz",
    "https://cran.r-project.org/src/contrib/spiderbar_0.2.5.tar.gz",
    "https://cran.r-project.org/src/contrib/Archive/spiderbar/spiderbar_0.2.5.tar.gz"
   ]
  },
  "test": {
   "commands": [
    "$R -e \"library('spiderbar')\"",
    "$R -e \"library('spiderbar')\""
   ]
  }
 },
 "osx_64_requirements": {
  "build": {
   "__set__": true,
   "elements": [
    "c_compiler_stub",
    "cxx_compiler_stub",
    "make"
   ]
  },
  "host": {
   "__set__": true,
   "elements": [
    "r-base",
    "r-rcpp"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "r-base",
    "r-rcpp"
   ]
  },
  "test": {
   "__set__": true,
   "elements": []
  }
 },
 "outputs_names": {
  "__set__": true,
  "elements": [
   "r-spiderbar"
  ]
 },
 "parsing_error": false,
 "platforms": [
  "linux_64",
  "osx_64"
 ],
 "pr_info": {
  "__lazy_json__": "pr_info/r-spiderbar.json"
 },
 "raw_meta_yaml": "{% set version = '0.2.5' %}\n{% set posix = 'm2-' if win else '' %}\n{% set native = 'm2w64-' if win else '' %}\n\npackage:\n  name: r-spiderbar\n  version: {{ version|replace(\"-\", \"_\") }}\n\nsource:\n  url:\n    - {{ cran_mirror }}/src/contrib/spiderbar_{{ version }}.tar.gz\n    - {{ cran_mirror }}/src/contrib/Archive/spiderbar/spiderbar_{{ version }}.tar.gz\n  sha256: 45b7f1c28d7764319d5222f170dd7c0733a8400ff5d2a9aba9d5f7a4eda81d7a\n\nbuild:\n  merge_build_host: True  # [win]\n  number: 0\n  skip: True  # [win]\n  rpaths:\n    - lib/R/lib/\n    - lib/\n\nrequirements:\n  build:\n    - {{ compiler('c') }}              # [not win]\n    - {{ compiler('m2w64_c') }}        # [win]\n    - {{ compiler('cxx') }}            # [not win]\n    - {{ compiler('m2w64_cxx') }}      # [win]\n    - {{ posix }}filesystem        # [win]\n    - {{ posix }}make\n    - {{ posix }}sed               # [win]\n    - {{ posix }}coreutils         # [win]\n    - {{ posix }}zip               # [win]\n    - cross-r-base {{ r_base }}    # [build_platform != target_platform]\n  host:\n    - r-base\n    - r-rcpp\n  run:\n    - r-base\n    - {{ native }}gcc-libs         # [win]\n    - r-rcpp\n\ntest:\n  commands:\n    - $R -e \"library('spiderbar')\"           # [not win]\n    - \"\\\"%R%\\\" -e \\\"library('spiderbar')\\\"\"  # [win]\n\nabout:\n  home: https://github.com/hrbrmstr/spiderbar\n  license: MIT\n  summary: The 'Robots Exclusion Protocol' <https://www.robotstxt.org/orig.html> documents a\n    set of standards for allowing or excluding robot/spider crawling of different areas\n    of site content. Tools are provided which wrap The 'rep-cpp' <https://github.com/seomoz/rep-cpp>\n    C++ library for processing these 'robots.txt' files.\n  license_family: MIT\n  license_file:\n    - '{{ environ[\"PREFIX\"] }}/lib/R/share/licenses/MIT'\n    - LICENSE\n\nextra:\n  recipe-maintainers:\n    - conda-forge/r\n",
 "req": {
  "__set__": true,
  "elements": [
   "c_compiler_stub",
   "cxx_compiler_stub",
   "make",
   "r-base",
   "r-rcpp"
  ]
 },
 "requirements": {
  "build": {
   "__set__": true,
   "elements": [
    "c_compiler_stub",
    "cxx_compiler_stub",
    "make"
   ]
  },
  "host": {
   "__set__": true,
   "elements": [
    "c_compiler_stub",
    "cxx_compiler_stub",
    "r-base",
    "r-rcpp"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "c_compiler_stub",
    "cxx_compiler_stub",
    "r-base",
    "r-rcpp"
   ]
  },
  "test": {
   "__set__": true,
   "elements": []
  }
 },
 "strong_exports": false,
 "total_requirements": {
  "build": {
   "__set__": true,
   "elements": [
    "c_compiler_stub",
    "cxx_compiler_stub",
    "make"
   ]
  },
  "host": {
   "__set__": true,
   "elements": [
    "r-base",
    "r-rcpp"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "r-base",
    "r-rcpp"
   ]
  },
  "test": {
   "__set__": true,
   "elements": []
  }
 },
 "url": [
  "https://cran.r-project.org/src/contrib/spiderbar_0.2.5.tar.gz",
  "https://cran.r-project.org/src/contrib/Archive/spiderbar/spiderbar_0.2.5.tar.gz",
  "https://cran.r-project.org/src/contrib/spiderbar_0.2.5.tar.gz",
  "https://cran.r-project.org/src/contrib/Archive/spiderbar/spiderbar_0.2.5.tar.gz",
  "https://cran.r-project.org/src/contrib/spiderbar_0.2.5.tar.gz",
  "https://cran.r-project.org/src/contrib/Archive/spiderbar/spiderbar_0.2.5.tar.gz",
  "https://cran.r-project.org/src/contrib/spiderbar_0.2.5.tar.gz",
  "https://cran.r-project.org/src/contrib/Archive/spiderbar/spiderbar_0.2.5.tar.gz"
 ],
 "version": "0.2.5",
 "version_pr_info": {
  "__lazy_json__": "version_pr_info/r-spiderbar.json"
 }
}