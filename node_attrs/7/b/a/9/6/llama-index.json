{
 "archived": false,
 "branch": "main",
 "conda-forge.yml": {
  "bot": {
   "automerge": true,
   "inspection": "update-grayskull"
  },
  "conda_build": {
   "error_overlinking": true
  },
  "conda_forge_output_validation": true,
  "github": {
   "branch_name": "main",
   "tooling_branch_name": "main"
  }
 },
 "feedstock_name": "llama-index",
 "hash_type": "sha256",
 "linux_64_meta_yaml": {
  "about": {
   "home": "https://github.com/run-llama/llama_index",
   "license": "MIT",
   "license_file": "LICENSE",
   "summary": "Interface between LLMs and your data"
  },
  "build": {
   "noarch": "python",
   "number": "0",
   "script": "PYTHON -m pip install . -vv"
  },
  "extra": {
   "recipe-maintainers": [
    "pavelzw"
   ]
  },
  "package": {
   "name": "llama-index",
   "version": "0.9.44"
  },
  "requirements": {
   "host": [
    "python >=3.8,<3.12",
    "pip",
    "poetry",
    "poetry-core"
   ],
   "run": [
    "dirtyjson >=1.0.8,<2.0.0",
    "networkx >=3.0",
    "types-protobuf >=4.24.0,<5.0.0",
    "sqlalchemy >=1.4.49",
    "python >=3.8,<3.12",
    "SQLAlchemy >=1.4.49",
    "greenlet !=0.4.17",
    "beautifulsoup4 >=4.12.2,<5.0.0",
    "dataclasses-json",
    "deprecated >=1.2.9.3",
    "fsspec >=2023.5.0",
    "httpx",
    "nest-asyncio >=1.5.8,<2.0.0",
    "nltk >=3.8.1,<4.0.0",
    "numpy",
    "openai >=1.1.0",
    "pandas",
    "tenacity >=8.2.0,<9.0.0",
    "tiktoken >=0.3.3",
    "typing-extensions >=4.5.0",
    "typing_inspect >=0.8.0",
    "requests >=2.31.0",
    "aiostream >=0.5.2,<0.6.0",
    "aiohttp >=3.8.6,<4.0.0"
   ],
   "run_constrained": [
    "langchain >=0.0.303",
    "asyncpg >=0.28.0,<0.29.0",
    "pgvector >=0.1.0,<0.2.0",
    "psycopg-binary >=3.1.12,<4.0.0",
    "optimum >=1.13.2,<2.0.0",
    "onnxruntime >=1.11.0",
    "datasets >=1.2.1",
    "evaluate",
    "protobuf >=3.20.1",
    "sentencepiece >=0.1.99,<0.2.0",
    "transformers >=4.34.0,<5.0.0",
    "guidance >=0.0.64,<1.0.0",
    "lm-format-enforcer >=0.4.3,<0.5.0",
    "jsonpath-ng >=1.6.0,<2.0.0",
    "rank-bm25 >=0.2.2,<0.3.0",
    "scikit-learn <1.3.0",
    "spacy >=3.7.1,<4.0.0"
   ]
  },
  "source": {
   "sha256": "9c5261e7016f5c5898970c3f8932e01daeaa80f62e9efa1405f0d7364f3aea33",
   "url": "https://pypi.io/packages/source/l/llama-index/llama_index-0.9.44.tar.gz"
  },
  "test": {
   "commands": [
    "pip check"
   ],
   "imports": [
    "llama_index"
   ],
   "requires": [
    "pip"
   ]
  }
 },
 "linux_64_requirements": {
  "build": {
   "__set__": true,
   "elements": []
  },
  "host": {
   "__set__": true,
   "elements": [
    "pip",
    "poetry",
    "poetry-core",
    "python"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "aiohttp",
    "aiostream",
    "beautifulsoup4",
    "dataclasses-json",
    "deprecated",
    "dirtyjson",
    "fsspec",
    "greenlet",
    "httpx",
    "nest-asyncio",
    "networkx",
    "nltk",
    "numpy",
    "openai",
    "pandas",
    "python",
    "requests",
    "sqlalchemy",
    "tenacity",
    "tiktoken",
    "types-protobuf",
    "typing-extensions",
    "typing_inspect"
   ]
  },
  "test": {
   "__set__": true,
   "elements": [
    "pip"
   ]
  }
 },
 "meta_yaml": {
  "about": {
   "home": "https://github.com/run-llama/llama_index",
   "license": "MIT",
   "license_file": "LICENSE",
   "summary": "Interface between LLMs and your data"
  },
  "build": {
   "noarch": "python",
   "number": "0",
   "script": "PYTHON -m pip install . -vv"
  },
  "extra": {
   "recipe-maintainers": [
    "pavelzw"
   ]
  },
  "package": {
   "name": "llama-index",
   "version": "0.9.44"
  },
  "requirements": {
   "host": [
    "python >=3.8,<3.12",
    "pip",
    "poetry",
    "poetry-core"
   ],
   "run": [
    "dirtyjson >=1.0.8,<2.0.0",
    "networkx >=3.0",
    "types-protobuf >=4.24.0,<5.0.0",
    "sqlalchemy >=1.4.49",
    "python >=3.8,<3.12",
    "SQLAlchemy >=1.4.49",
    "greenlet !=0.4.17",
    "beautifulsoup4 >=4.12.2,<5.0.0",
    "dataclasses-json",
    "deprecated >=1.2.9.3",
    "fsspec >=2023.5.0",
    "httpx",
    "nest-asyncio >=1.5.8,<2.0.0",
    "nltk >=3.8.1,<4.0.0",
    "numpy",
    "openai >=1.1.0",
    "pandas",
    "tenacity >=8.2.0,<9.0.0",
    "tiktoken >=0.3.3",
    "typing-extensions >=4.5.0",
    "typing_inspect >=0.8.0",
    "requests >=2.31.0",
    "aiostream >=0.5.2,<0.6.0",
    "aiohttp >=3.8.6,<4.0.0"
   ],
   "run_constrained": [
    "langchain >=0.0.303",
    "asyncpg >=0.28.0,<0.29.0",
    "pgvector >=0.1.0,<0.2.0",
    "psycopg-binary >=3.1.12,<4.0.0",
    "optimum >=1.13.2,<2.0.0",
    "onnxruntime >=1.11.0",
    "datasets >=1.2.1",
    "evaluate",
    "protobuf >=3.20.1",
    "sentencepiece >=0.1.99,<0.2.0",
    "transformers >=4.34.0,<5.0.0",
    "guidance >=0.0.64,<1.0.0",
    "lm-format-enforcer >=0.4.3,<0.5.0",
    "jsonpath-ng >=1.6.0,<2.0.0",
    "rank-bm25 >=0.2.2,<0.3.0",
    "scikit-learn <1.3.0",
    "spacy >=3.7.1,<4.0.0"
   ]
  },
  "source": {
   "sha256": "9c5261e7016f5c5898970c3f8932e01daeaa80f62e9efa1405f0d7364f3aea33",
   "url": "https://pypi.io/packages/source/l/llama-index/llama_index-0.9.44.tar.gz"
  },
  "test": {
   "commands": [
    "pip check"
   ],
   "imports": [
    "llama_index"
   ],
   "requires": [
    "pip"
   ]
  }
 },
 "name": "llama-index",
 "outputs_names": {
  "__set__": true,
  "elements": [
   "llama-index"
  ]
 },
 "parsing_error": false,
 "platforms": [
  "linux_64"
 ],
 "pr_info": {
  "__lazy_json__": "pr_info/llama-index.json"
 },
 "raw_meta_yaml": "{% set name = \"llama-index\" %}\n{% set version = \"0.9.44\" %}\n\npackage:\n  name: {{ name|lower }}\n  version: {{ version }}\n\nsource:\n  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/llama_index-{{ version }}.tar.gz\n  sha256: 9c5261e7016f5c5898970c3f8932e01daeaa80f62e9efa1405f0d7364f3aea33\n\nbuild:\n  noarch: python\n  script: {{ PYTHON }} -m pip install . -vv\n  number: 0\n\nrequirements:\n  host:\n    - python >=3.8,<3.12\n    - pip\n    - poetry\n    - poetry-core\n  run:\n    - dirtyjson >=1.0.8,<2.0.0\n    - networkx >=3.0\n    - types-protobuf >=4.24.0,<5.0.0\n    - sqlalchemy >=1.4.49\n    - python >=3.8,<3.12\n    - SQLAlchemy >=1.4.49\n    - greenlet !=0.4.17\n    - beautifulsoup4 >=4.12.2,<5.0.0\n    - dataclasses-json\n    - deprecated >=1.2.9.3\n    - fsspec >=2023.5.0\n    - httpx\n    - nest-asyncio >=1.5.8,<2.0.0\n    - nltk >=3.8.1,<4.0.0\n    - numpy\n    - openai >=1.1.0\n    - pandas\n    - tenacity >=8.2.0,<9.0.0\n    - tiktoken >=0.3.3\n    - typing-extensions >=4.5.0\n    - typing_inspect >=0.8.0\n    - requests >=2.31.0\n    - aiostream >=0.5.2,<0.6.0\n    - aiohttp >=3.8.6,<4.0.0\n  run_constrained:\n    - langchain >=0.0.303\n    - asyncpg >=0.28.0,<0.29.0\n    - pgvector >=0.1.0,<0.2.0\n    - psycopg-binary >=3.1.12,<4.0.0\n    - optimum >=1.13.2,<2.0.0\n    - onnxruntime >=1.11.0\n    - datasets >=1.2.1\n    - evaluate\n    - protobuf >=3.20.1\n    - sentencepiece >=0.1.99,<0.2.0\n    - transformers >=4.34.0,<5.0.0\n    - guidance >=0.0.64,<1.0.0\n    - lm-format-enforcer >=0.4.3,<0.5.0\n    - jsonpath-ng >=1.6.0,<2.0.0\n    - rank-bm25 >=0.2.2,<0.3.0\n    - scikit-learn <1.3.0\n    - spacy >=3.7.1,<4.0.0\n\n\ntest:\n  imports:\n    - llama_index\n  commands:\n    - pip check\n  requires:\n    - pip\n\nabout:\n  home: https://github.com/run-llama/llama_index\n  summary: Interface between LLMs and your data\n  license: MIT\n  license_file: LICENSE\n\nextra:\n  recipe-maintainers:\n    - pavelzw\n",
 "req": {
  "__set__": true,
  "elements": [
   "aiohttp",
   "aiostream",
   "beautifulsoup4",
   "dataclasses-json",
   "deprecated",
   "dirtyjson",
   "fsspec",
   "greenlet",
   "httpx",
   "nest-asyncio",
   "networkx",
   "nltk",
   "numpy",
   "openai",
   "pandas",
   "pip",
   "poetry",
   "poetry-core",
   "python",
   "requests",
   "sqlalchemy",
   "tenacity",
   "tiktoken",
   "types-protobuf",
   "typing-extensions",
   "typing_inspect"
  ]
 },
 "requirements": {
  "build": {
   "__set__": true,
   "elements": []
  },
  "host": {
   "__set__": true,
   "elements": [
    "pip",
    "poetry",
    "poetry-core",
    "python"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "aiohttp",
    "aiostream",
    "beautifulsoup4",
    "dataclasses-json",
    "deprecated",
    "dirtyjson",
    "fsspec",
    "greenlet",
    "httpx",
    "nest-asyncio",
    "networkx",
    "nltk",
    "numpy",
    "openai",
    "pandas",
    "python",
    "requests",
    "sqlalchemy",
    "tenacity",
    "tiktoken",
    "types-protobuf",
    "typing-extensions",
    "typing_inspect"
   ]
  },
  "test": {
   "__set__": true,
   "elements": [
    "pip"
   ]
  }
 },
 "strong_exports": false,
 "total_requirements": {
  "build": {
   "__set__": true,
   "elements": []
  },
  "host": {
   "__set__": true,
   "elements": [
    "pip",
    "poetry",
    "poetry-core",
    "python >=3.8,<3.12"
   ]
  },
  "run": {
   "__set__": true,
   "elements": [
    "SQLAlchemy >=1.4.49",
    "aiohttp >=3.8.6,<4.0.0",
    "aiostream >=0.5.2,<0.6.0",
    "beautifulsoup4 >=4.12.2,<5.0.0",
    "dataclasses-json",
    "deprecated >=1.2.9.3",
    "dirtyjson >=1.0.8,<2.0.0",
    "fsspec >=2023.5.0",
    "greenlet !=0.4.17",
    "httpx",
    "nest-asyncio >=1.5.8,<2.0.0",
    "networkx >=3.0",
    "nltk >=3.8.1,<4.0.0",
    "numpy",
    "openai >=1.1.0",
    "pandas",
    "python >=3.8,<3.12",
    "requests >=2.31.0",
    "sqlalchemy >=1.4.49",
    "tenacity >=8.2.0,<9.0.0",
    "tiktoken >=0.3.3",
    "types-protobuf >=4.24.0,<5.0.0",
    "typing-extensions >=4.5.0",
    "typing_inspect >=0.8.0"
   ]
  },
  "test": {
   "__set__": true,
   "elements": [
    "pip"
   ]
  }
 },
 "url": "https://pypi.io/packages/source/l/llama-index/llama_index-0.9.44.tar.gz",
 "version": "0.9.44",
 "version_pr_info": {
  "__lazy_json__": "version_pr_info/llama-index.json"
 }
}